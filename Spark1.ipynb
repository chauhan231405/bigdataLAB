{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM40xfTJAYlFtOoQmD0KAx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chauhan231405/bigdataLAB/blob/main/Spark1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILdLkG1BB7l0",
        "outputId": "78f9bbc9-2383-423c-98da-8cb306d3542e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=a854cdeb5133b5e1f1c742af795651f3cb427a7cbdf27d24d13eb39f17508c56\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf,SparkContext\n",
        "conf=SparkConf().setAppName('abc').setMaster('local') #\n",
        "sc=SparkContext(conf=conf)\n",
        "sc.setLogLevel('ERROR')\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('abc').config('','').getOrCreate()\n",
        "# NUMPY Dense Vector\n",
        "import numpy as np\n",
        "v1=np.array([1,2,3,4,5])\n",
        "print(v1)\n",
        "# simple python list\n",
        "v2=[1,2,3,4,5,6]\n",
        "print(v2)\n",
        "# Sparce & dense spark vector\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "v3=Vectors.dense([3,4,5,6])\n",
        "print(v3)\n",
        "v4 = Vectors.sparse(3, [0, 2], [1.0, 3.0])\n",
        "print(v4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x4qtaDBC9Pa",
        "outputId": "3dd14ea9-771c-430c-b709-ebfa71367274"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n",
            "[1, 2, 3, 4, 5, 6]\n",
            "[3.0,4.0,5.0,6.0]\n",
            "(3,[0,2],[1.0,3.0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('data.csv',header=True,inferSchema=True) # header = None\n",
        "df.show(5,0) # 0 doesnot truncate displaying columns, useful in large dataset"
      ],
      "metadata": {
        "id": "SiblVWrEDLwr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "9131c800-4b3e-43bd-89b9-0d4960a4143c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c171f26e6582>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# header = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0 doesnot truncate displaying columns, useful in large dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/data.csv."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "d54GguJjDLzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "0mZc4AHxDL4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "5a033872-9171-4e70-a2f1-c65d1c505377"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3c9a60fd698f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('Grades').distinct().count()"
      ],
      "metadata": {
        "id": "RcuexloZDL6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6b0217-dd41-4b84-c2f7-193188e01682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "ZVfL2KY4DL9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278747cd-b92b-49d4-aeb0-3d01e6394fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Time_to_Study: integer (nullable = true)\n",
            " |-- Grades: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "0J3EYQ-_DMCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c1aa92-6e41-4008-c654-1bfafb3e6664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+\n",
            "|Time_to_Study|Grades|\n",
            "+-------------+------+\n",
            "|            1|   1.5|\n",
            "|            5|   2.7|\n",
            "|            7|   3.1|\n",
            "|            3|   2.1|\n",
            "|            2|   1.8|\n",
            "|            9|   3.9|\n",
            "|            6|   2.9|\n",
            "|           12|   4.5|\n",
            "|           11|   4.3|\n",
            "|            2|   1.8|\n",
            "|            4|   2.4|\n",
            "|            8|   3.5|\n",
            "|           13|   4.8|\n",
            "|            9|   3.9|\n",
            "|           14|   5.0|\n",
            "|           10|   4.1|\n",
            "|            6|   2.9|\n",
            "|           12|   4.5|\n",
            "|            1|   1.5|\n",
            "|            4|   2.4|\n",
            "+-------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCmGSFhKDtcz",
        "outputId": "56609a42-22d1-4072-ef5a-2a6d8f02a1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------------------+\n",
            "|summary|    Time_to_Study|            Grades|\n",
            "+-------+-----------------+------------------+\n",
            "|  count|               50|                50|\n",
            "|   mean|             7.12|3.2220000000000004|\n",
            "| stddev|4.048884956102742|1.1047744252164082|\n",
            "|    min|                1|               1.5|\n",
            "|    max|               14|               5.0|\n",
            "+-------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a feature array by omitting the last column\n",
        "feature_cols = df.columns[:-1]\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vect_assembler = VectorAssembler(inputCols = feature_cols, outputCol=\"features\")\n",
        "#Utilize Assembler created above in order to add the feature column\n",
        "data_w_features = vect_assembler.transform(df)"
      ],
      "metadata": {
        "id": "A4AefxvWDtfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data = data_w_features.select(\"features\",\"Grades\")\n",
        "finalized_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dckbKgivDtkB",
        "outputId": "215dbec3-8b7b-4897-b970-bef876a10cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|features|Grades|\n",
            "+--------+------+\n",
            "|   [1.0]|   1.5|\n",
            "|   [5.0]|   2.7|\n",
            "|   [7.0]|   3.1|\n",
            "|   [3.0]|   2.1|\n",
            "|   [2.0]|   1.8|\n",
            "|   [9.0]|   3.9|\n",
            "|   [6.0]|   2.9|\n",
            "|  [12.0]|   4.5|\n",
            "|  [11.0]|   4.3|\n",
            "|   [2.0]|   1.8|\n",
            "|   [4.0]|   2.4|\n",
            "|   [8.0]|   3.5|\n",
            "|  [13.0]|   4.8|\n",
            "|   [9.0]|   3.9|\n",
            "|  [14.0]|   5.0|\n",
            "|  [10.0]|   4.1|\n",
            "|   [6.0]|   2.9|\n",
            "|  [12.0]|   4.5|\n",
            "|   [1.0]|   1.5|\n",
            "|   [4.0]|   2.4|\n",
            "+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "train_dataset, test_dataset = finalized_data.randomSplit([0.7, 0.3])\n",
        "print(df.count())\n",
        "print(train_dataset.count())\n",
        "print(test_dataset.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0jgabxqDtmh",
        "outputId": "efb3423d-37fc-4467-d6f1-10cf01eb819e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "42\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Linear Regression class called LinearRegression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "LinReg = LinearRegression(featuresCol=\"features\", labelCol=\"Grades\")"
      ],
      "metadata": {
        "id": "YFu02ZiCD52i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training and testing\n",
        "#Train the model on the training using fit() method.\n",
        "model = LinReg.fit(train_dataset)\n",
        "#Predict the Grades using the evulate method\n",
        "pred = model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "y_R4gz--D54y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d616A8VBD57F",
        "outputId": "71f8d20c-f7fb-412d-a13f-a7e0d7b0eea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------------------+\n",
            "|features|Grades|        prediction|\n",
            "+--------+------+------------------+\n",
            "|   [1.0]|   1.5| 1.559778872831174|\n",
            "|   [1.0]|   1.5| 1.559778872831174|\n",
            "|   [2.0]|   1.8|1.8325686363824594|\n",
            "|   [2.0]|   1.8|1.8325686363824594|\n",
            "|   [5.0]|   2.7|2.6509379270363165|\n",
            "|  [12.0]|   4.5| 4.560466271895316|\n",
            "|  [12.0]|   4.5| 4.560466271895316|\n",
            "|  [14.0]|   5.0| 5.106045798997887|\n",
            "+--------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find out coefficient value\n",
        "coefficient = model.coefficients\n",
        "print (\"The coefficient of the model is : %a\" %coefficient)\n",
        "#Find out intercept Value\n",
        "intercept = model.intercept\n",
        "print (\"The Intercept of the model is : %f\" %intercept)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwDy1rLpD59h",
        "outputId": "7c96de7a-5c23-479c-ecd9-5f2e3eb85b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The coefficient of the model is : DenseVector([0.2728])\n",
            "The Intercept of the model is : 1.286989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean␣↪Square Error(RMSE) and R-Square\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluation = RegressionEvaluator(labelCol=\"Grades\", predictionCol=\"prediction\")\n",
        "# Root Mean Square Error\n",
        "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "# Mean Square Error\n",
        "mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "# Mean Absolute Error\n",
        "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "# r2 - coefficient of determination\n",
        "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRsDqZymD6AO",
        "outputId": "05795ca0-a5b3-42ee-8885-297909a8edf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.061\n",
            "MSE: 0.004\n",
            "MAE: 0.058\n",
            "r2: 0.998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kv_M_RorEVRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}